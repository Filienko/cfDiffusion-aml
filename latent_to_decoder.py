#!/usr/bin/env python
"""
Decode latent variables to gene expression data using a pretrained VAE.

This script:
1. Loads latent variables generated by cell_sample.py
2. Uses a pretrained VAE to decode them to gene expression data
3. Saves the decoded data in a specified output directory
"""

import os
import argparse
import numpy as np
import torch
import glob
import sys
from tqdm import tqdm

# Add parent directory to path for VAE imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from VAE.VAE_model import VAE

def load_VAE(vae_path, num_genes, hidden_dim=128):
    """
    Load the trained VAE model
    
    Args:
        vae_path: Path to the VAE checkpoint
        num_genes: Number of genes in the dataset
        hidden_dim: Dimension of the latent space
        
    Returns:
        The loaded VAE model
    """
    print(f"Loading VAE from {vae_path}")
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    autoencoder = VAE(
        num_genes=num_genes,
        device=device,
        seed=0,
        loss_ae='mse',
        hidden_dim=hidden_dim,
        decoder_activation='ReLU',
    )
    autoencoder.load_state_dict(torch.load(vae_path, map_location=device))
    # Don't call eval() or train() as they are overridden in this implementation
    return autoencoder

def decode_latent_files(latent_dir, vae_path, output_dir, num_genes, batch_size=256):
    """
    Decode all latent files in a directory to gene expression data
    
    Args:
        latent_dir: Directory containing latent variable files
        vae_path: Path to the VAE checkpoint
        output_dir: Directory to save the decoded files
        num_genes: Number of genes in the dataset
        batch_size: Batch size for decoding
    """
    # Load the VAE model
    vae = load_VAE(vae_path, num_genes)
    
    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)
    
    # Find all .npy files in the latent directory
    latent_files = glob.glob(os.path.join(latent_dir, "*.npy"))
    print(f"Found {len(latent_files)} latent files to decode.")
    
    # Process each latent file
    for latent_file in latent_files:
        file_basename = os.path.basename(latent_file)
        output_file = os.path.join(output_dir, f"expr_{file_basename}")
        
        # Skip if the output file already exists
        if os.path.exists(output_file):
            print(f"Skipping {file_basename}, output file already exists.")
            continue
        
        print(f"Processing {file_basename}...")
        
        # Load the latent variables
        latent_vars = np.load(latent_file)
        print(f"  Loaded latent variables with shape {latent_vars.shape}")
        
        # Decode in batches to avoid memory issues
        decoded_data = []
        num_samples = latent_vars.shape[0]
        device = vae.device
        
        with torch.no_grad():
            for i in tqdm(range(0, num_samples, batch_size), desc="Decoding batches"):
                # Get batch
                end_idx = min(i + batch_size, num_samples)
                batch = latent_vars[i:end_idx]
                
                # Convert to tensor and move to device
                batch_tensor = torch.tensor(batch, dtype=torch.float32).to(device)
                
                # Decode batch using forward method with return_decoded=True
                decoded_batch = vae(batch_tensor, return_decoded=True)
                
                # Move to CPU and convert to numpy
                decoded_batch = decoded_batch.cpu().detach().numpy()
                
                # Append to list
                decoded_data.append(decoded_batch)
                
                # Clear GPU memory if using CUDA
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
        
        # Concatenate all batches
        decoded_data = np.vstack(decoded_data)
        print(f"  Decoded data shape: {decoded_data.shape}")
        
        # Save the decoded data
        np.save(output_file, decoded_data)
        print(f"  Saved decoded data to {output_file}")

def parse_args():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(description="Decode latent variables to gene expression data")
    
    parser.add_argument("--latent_dir", type=str, required=True,
                        help="Directory containing latent variable files")
    parser.add_argument("--vae_path", type=str, required=True,
                        help="Path to the VAE checkpoint")
    parser.add_argument("--output_dir", type=str, default="./decoded_expression",
                        help="Directory to save the decoded files")
    parser.add_argument("--num_genes", type=int, required=True,
                        help="Number of genes in the dataset")
    parser.add_argument("--batch_size", type=int, default=256,
                        help="Batch size for decoding")
    
    return parser.parse_args()

def main():
    """Main function"""
    args = parse_args()
    
    print("Starting decoding process...")
    print(f"Latent directory: {args.latent_dir}")
    print(f"VAE path: {args.vae_path}")
    print(f"Output directory: {args.output_dir}")
    print(f"Number of genes: {args.num_genes}")
    print(f"Batch size: {args.batch_size}")
    
    decode_latent_files(
        latent_dir=args.latent_dir,
        vae_path=args.vae_path,
        output_dir=args.output_dir,
        num_genes=args.num_genes,
        batch_size=args.batch_size
    )
    
    print("Decoding process completed!")

if __name__ == "__main__":
    main()
